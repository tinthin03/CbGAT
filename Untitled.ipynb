{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8ee3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1., 1., 1.]), tensor([2., 2., 2.])]\n",
      "tensor([1., 1., 1., 2., 2., 2.])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0e8ec3b9ce5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ones = torch.ones(3)\n",
    "x = []\n",
    "x.append(ones*1)\n",
    "x.append(ones*2)\n",
    "print(x)\n",
    "y= torch.cat(x, dim=0)\n",
    "print(y)\n",
    "z= torch.cat(x, dim=1)\n",
    "print(z)http://127.0.0.1:19999/notebooks/RNNLogic-main/codes/Untitled.ipynb?kernel_name=python3#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68593852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False,  True,  True, False, False,  True])\n",
      "pos: tensor([0.3000, 1.1200, 0.4000], device='cuda:0')\n",
      "neg: tensor([0.1200, 0.1000, 0.5000], device='cuda:0')\n",
      "num: tensor([2, 3, 3], device='cuda:0')\n",
      "(pos - neg) / num : tensor([ 0.0900,  0.3400, -0.0333], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.tensor\n",
    "def list2mask(a, N):\n",
    "    if isinstance(a, list):\n",
    "        a = torch.LongTensor(a)\n",
    "    m = torch.zeros(N).to(a.device).bool()\n",
    "    m[a] = True\n",
    "    return m\n",
    "E = 15\n",
    "num_rule = 3\n",
    "t_list = [4,11]\n",
    "mask = list2mask(t_list, E)\n",
    "crule = tensor([0,0,1., 1., 1., 2., 2., 2.]).long()\n",
    "centity = tensor([4,1,2., 4., 4., 7., 8., 11.]).long()\n",
    "cscore =  tensor([0.3,0.12,0.1, 0.54, 0.58, 0.2, 0.3, 0.4])\n",
    "indices = torch.stack([crule, centity], 0)\n",
    "\n",
    "\n",
    "def cvalue(cscore):\n",
    "    if cscore.size(0) == 0:\n",
    "        return torch.zeros(num_rule).cuda()\n",
    "    return torch.sparse.sum(torch.sparse.FloatTensor(\n",
    "        indices,\n",
    "        cscore,\n",
    "        torch.Size([num_rule, E])#统计各个规则的得分之和，对同一规则的各个pgnd得分做加和\n",
    "    ).cuda(), -1).to_dense()\n",
    "\n",
    "pos = cvalue(cscore * mask[centity])\n",
    "\n",
    "print (mask[centity])\n",
    "print (\"pos:\",pos)\n",
    "cweight = tensor([1,1,1,1,1,1,1,1]).long()\n",
    "neg = cvalue(cscore * ~mask[centity])#该样本的各个规则的负得分\n",
    "print (\"neg:\",neg)\n",
    "score = cvalue(cscore)\n",
    "num = cvalue(cweight).clamp(min=0.001)#加权和的分母\n",
    "print (\"num:\",num)\n",
    "def eval_ctx(local_ctx):\n",
    "    #local_ctx['self'] = self\n",
    "    return lambda x: eval(x, globals(), local_ctx)\n",
    "_args = dict()\n",
    "_args['rule_value_def'] = '(pos - neg) / num'\n",
    "def arg(name, apply=None):\n",
    "        # print(self._args[name])\n",
    "        v = _args[name]\n",
    "        if apply is None:\n",
    "            if v is None:\n",
    "                return None\n",
    "            return eval(v)\n",
    "        return apply(v)\n",
    "#取参数'rule_value_def'同名的项（可能是pos、neg等）为规则的打分\n",
    "value = arg('rule_value_def', apply=eval_ctx(locals()))\n",
    "print (_args['rule_value_def'],\":\",value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ca7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict tail on E entities: tensor([0.0000, 0.1200, 0.1000, 0.0000, 1.4200, 0.0000, 0.0000, 0.2000, 0.3000,\n",
      "        0.0000, 0.0000, 0.4000, 0.0000, 0.0000, 0.0000])\n",
      "mask tensor([False, False, False, False,  True, False, False, False, False, False,\n",
      "        False,  True, False, False, False])\n",
      "softmax score tensor([0.0515, 0.0580, 0.0569, 0.0515, 0.2129, 0.0515, 0.0515, 0.0629, 0.0695,\n",
      "        0.0515, 0.0515, 0.0768, 0.0515, 0.0515, 0.0515])\n",
      "ng tensor([0.0515, 0.0580, 0.0569, 0.0515, 0.0515, 0.0515, 0.0629, 0.0695, 0.0515,\n",
      "        0.0515, 0.0515, 0.0515, 0.0515])\n",
      "ng loss tensor(0.7200, device='cuda:0')\n",
      "total loss tensor(0.7200, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "def index_select(tensor, index):\n",
    "    if training:\n",
    "        if not isinstance(index, torch.Tensor):\n",
    "            index = torch.tensor(index)\n",
    "        index = index.to(tensor.device)\n",
    "        return tensor.index_select(0, index).squeeze(0)\n",
    "    else:\n",
    "        return tensor[index]\n",
    "        \n",
    "sc = torch.sparse.sum(torch.sparse.FloatTensor(\n",
    "                    torch.stack([centity, crule], dim=0),\n",
    "                    index_select(cscore, torch.arange(cscore.size(0))),\n",
    "                    torch.Size([E, num_rule])\n",
    "                ), -1).to_dense()\n",
    "print(\"predict tail on E entities:\",sc)\n",
    "print(\"mask\",mask)\n",
    "loss = torch.tensor(0.0).cuda() + 0.0\n",
    "sc = sc.softmax(dim=-1)#归一化得分\n",
    "ng = sc.masked_select(~mask.bool())#规则推出的pgnd里存在错误的，将pgnd的score直接加和作为loss\n",
    "print(\"softmax score\",sc)\n",
    "print(\"ng\",ng)\n",
    "loss+=neg.sum()\n",
    "print(\"ng loss\",loss)\n",
    "t_list = [4,11]\n",
    "for t in t_list:\n",
    "    s = sc[t]\n",
    "    wrong = (ng > s)\n",
    "    loss += ((ng - s) * wrong).sum() / wrong.sum().clamp(min=1)\n",
    "print(\"total loss\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import groundings,em_model\n",
    "from knowledge_graph_utils import *\n",
    "DATA_EM_DIR          = \"./data_em/FB15k-237\" \n",
    "dataset = load_dataset(f\"{DATA_EM_DIR}\")\n",
    "ground = groundings.init_groundings()\n",
    "rule = [201, 107, 140] \n",
    "print(1,\"rule\")\n",
    "for h in dataset['Rh'][1]:\n",
    "    print(\"head\",h)\n",
    "    gr = em_model.calc_groundings(h, rule,count=True)\n",
    "    print(gr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
